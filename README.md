## Video-Datasets


### Fall-Down-Detection

<br> [UR Fall Detection Dataset](http://fenix.ur.edu.pl/~mkepski/ds/uf.html):Michal Kępski, Interdisciplinary Centre for Computational Modelling, University of Rzeszow

<br> [Multiple cameras fall dataset](https://www.iro.umontreal.ca/~labimage/Dataset/): This dataset contain 24 scenarios recorded with 8 IP video cameras. The first 22 first scenarios contain a fall and confounding events, the last 2 ones contain only confounding events.

<br> [Video Datasets](http://videodatasets.org/): This web site contains links to a number of video datasets used for computer vision research and created over a number of years by teams working with/in collaboration with  Prof. Sergio A Velastin, professor of Applied Computer Vision, recently a UC3M-Conex Marie Curie Research Professor at the Applied Artificial Intelligence Research Group, Universidad Carlos III de Madrid (Spain) and former director of the Digital Imaging Research Centre (Kingston University London, UK). He is now Visiting Professor at Queen Mary University of London, UK and at Universidad Carlos III de Madrid, Spain

<br> [ViHASi: Virtual Human Action Silhouette Data](http://velastin.dynu.com/VIHASI/): for the Evaluation of Silhouette-Based Action Recognition Methods and the Evaluation of Silhouette-Based Pose Recovery Methods (NEW) (last updated on the 13th of January 2009)

<br> [MuHAVi: Multicamera Human Action Video Data](http://velastin.dynu.com/MuHAVi-MAS/): including selected action sequences with MAS: Manually Annotated Silhouette Data MuHAVi-uncut: Full videos with realistic Silhoutte Data for the evaluation of human action recognition methods (Last updated September 2017) 

<br> [FALL-UP DATASET](https://sites.google.com/up.edu.mx/har-up/): The aim of this project is to assist elderly people using novel human activity recognition machine learning methods. Additional: [Github](https://github.com/jpnm561/HAR-UP)

### Human-Actions

<br> [GAMING DATASETS](http://velastin.dynu.com/G3D/index.html): We captured single and multiplayer gaming datasets for public use, both containing synchronised colour, depth and skeleton data. For an overview of these datasets please see the table below, for more details or to download a dataset please follow the dataset links. Due to the formats selected, it is possible to view all the recorded data and metadata without any special software tools. For compatibility the same formats were used for both datasets. 

<br> [PAMELA UANDES DATASET](http://videodatasets.org/PAMELA-UANDES): The objective of the project is to study passenger behaviour and its relation to the environment, as they get on and off a public transport vehicle, in this case a full-scale metropolitan train model. 

<br> [BOSS DATASET](http://videodatasets.org/BOSSdata): The BOSS dataset is a fairly realistic dataset for pose, action and interaction recognition. It was originally captured as part of the Eureka's Celtic Initiative "BOSS : On Board Wireless Secured Video Surveillance BOSS" project. It consists of video/audio recordings of acted actions inside a moving train. It used multiple calibrated cameras.

### Object

<br> [THE UTUAV URBAN TRAFFIC DATASET](http://videodatasets.org/UTUAV): We present the UTUAV dataset which consists of three different scenes captured in the second largest city of Colombia: Medellín. Road user classes representative of those in emerging countries such as Colombia, have been choosen: motorcycles (MC), light vehicles (LV) and heavy vehicles (HV). 

<br> [MOTOR BIKE DATASET](http://videodatasets.org/UrbanMotorbike): We captured a video sequence datasets for public use, which contain images taken with a Phantom 4® drone, with an HD camera under windy conditions, which affected the image stabilizer capabilities.  Images were resized to 640 x 364 pixels, containing 41,040 to 56,975 ROI annotated objects, with a minimal height size set to 25 pixels. 60% of the annotated data corresponds to occluded motorcycles. Objects partially occluded with height less than 25 pixels were not annotated.

